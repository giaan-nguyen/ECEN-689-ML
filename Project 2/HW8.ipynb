{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this Notebook we work on Titanic passengers database and make predictions on their survival. We use scikit-learn package, please feel free to learn classification in scikit from here https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "Most of the functions needed for the homework are in the notebook, please look at the arguments for each function and play with them to improve your understanding**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "# Load dataset.\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000  First        C   \n",
       "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore the dataset by looking at the features. For improving the accuracy you can play with features as well, if you feel some of the features are not needed, you can drop them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>First</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>D</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
       "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
       "1    male  54.0                   0      0  51.8625   First        E   \n",
       "2  female  58.0                   0      0  26.5500   First        C   \n",
       "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
       "4    male  34.0                   0      0  13.0000  Second        D   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     y  \n",
       "1  Southampton     y  \n",
       "2  Southampton     y  \n",
       "3  Southampton     y  \n",
       "4  Southampton     y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfeval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse the dataset, here you find the count, statistics of dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at labeled data of both training and evaluation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the next few plots you can observe few more things in the dataset like distribution of age of passengers. Make good observations on the features, it might help you push your prediction accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain.age.hist(bins=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make some observations on the unfortundate :( data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain.embark_town.value_counts().plot(kind='barh')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Survived passengers for each class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([dftrain, y_train], axis=1).groupby('class').survived.mean().plot(kind='barh').set_xlabel('% survive')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alright! lets get started! by now you must be wondering how to run learning algorithms on categorial features(we care only about numbers right!). Dataset has categorial features like embark_town, deck, class etc. These are strings but all the algorithms need numericals right. So, we have to change categorial features to numerical features. There are three different ways to do that, here we present one and the easiest way to do that**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dummies\n",
    "dftrain = pd.get_dummies(dftrain, prefix_sep='_', drop_first=False)\n",
    "dfeval = pd.get_dummies(dfeval, prefix_sep='_', drop_first=False)\n",
    "dftrain.shape\n",
    "dfeval.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we are dropping one of the features to align training and evaluation datasets, you can use this to drop features you might consider unnecessary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = dftrain.drop(columns=\"deck_G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfeval.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{TASK 1. }}$ *You will implement a Decision tree classifer on the Dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.24242424242425 %\n"
     ]
    }
   ],
   "source": [
    " dtc = DecisionTreeClassifier(max_depth=1)\n",
    "dtc.fit(dftrain, y_train)\n",
    "y_pred = dtc.predict(dfeval)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{TASK 2. }}$ *Now perform adaptive boosting for a decision tree classifer. Please play with the depth of the tree.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adaptive boosting for Decision Tree Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.75757575757575 %\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),n_estimators=50,\n",
    "                         learning_rate=1)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(dftrain, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(dfeval)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{blue}{\\textit{Observations: }}$ In fact, when we run different values for max_depth, we see that the highest accuracies are attained somewhere around max_depth values of 100-500. This range is a ballpark estimate of that we will use later for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 5 \t Accuracy: 79.16666666666666 %\n",
      "Max Depth: 10 \t Accuracy: 80.68181818181817 %\n",
      "Max Depth: 50 \t Accuracy: 82.1969696969697 %\n",
      "Max Depth: 100 \t Accuracy: 82.95454545454545 %\n",
      "Max Depth: 500 \t Accuracy: 82.57575757575758 %\n",
      "Max Depth: 1000 \t Accuracy: 82.57575757575758 %\n"
     ]
    }
   ],
   "source": [
    "depth_vals = [5, 10, 50, 100, 500, 1000]\n",
    "\n",
    "for depth in depth_vals:\n",
    "    abc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=depth),n_estimators=50,\n",
    "                         learning_rate=1)\n",
    "    # Train Adaboost Classifer\n",
    "    model = abc.fit(dftrain, y_train)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = model.predict(dfeval)\n",
    "    print(\"Max Depth:\",depth,\"\\t\",\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{TASK 3. }}$ *Using the SVM classifer on the dataset, play with different kernels and present your observations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear SVM classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.37878787878788 %\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(dftrain, y_train)\n",
    "y_pred = svclassifier.predict(dfeval)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{blue}{\\textit{Observations: }}$ When testing different kernels - linear, sigmoid, rbf, degree-2 poly - on the SVC model, we see that the degree-2 poly attains the highest accuracy, followed by the linear kernel. (Any degree higher than 2 had a significantly longer computational time and thus was not considered.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear \t Accuracy: 75.37878787878788 %\n",
      "Kernel: sigmoid \t Accuracy: 62.5 %\n",
      "Kernel: rbf \t Accuracy: 71.96969696969697 %\n",
      "Kernel: poly \t Accuracy: 79.16666666666666 %\n"
     ]
    }
   ],
   "source": [
    "kernel_types = ['linear','sigmoid','rbf','poly']\n",
    "\n",
    "for kern in kernel_types:\n",
    "    if kern != 'poly':\n",
    "        svclassifier = SVC(kernel=kern,gamma='auto')\n",
    "    else:\n",
    "        svclassifier = SVC(kernel=kern,gamma='auto',degree=2)\n",
    "    svclassifier.fit(dftrain, y_train)\n",
    "    y_pred = svclassifier.predict(dfeval)\n",
    "    print(\"Kernel:\", kern, \"\\t\", \"Accuracy:\",metrics.accuracy_score(y_eval, y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{TASK 4. }}$ *Apply Boosting to the SVM classifers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.24242424242425 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svc=SVC(probability=True, kernel='linear')\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc =AdaBoostClassifier(n_estimators=90, base_estimator=svc,learning_rate=.01)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(dftrain, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(dfeval)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred)*100,\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use SVM classifier with polynomial or radial basis function as kernel and later apply boosting and share your observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{blue}{\\textit{Observations: }}$\n",
    "\n",
    "Interestingly, applying AdaBoost to a SVM classifier (regardless of using 'linear', 'poly' (deg 2), or 'rbf' for kernel) does little to change the accuracy from the original counterparts. In fact, during some runs, AdaBoost lowered the accuracy for some classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO BOOSTING.  Kernel: poly \t Accuracy: 66.28787878787878 %\n",
      "WITH BOOSTING.  Kernel: poly \t Accuracy: 64.01515151515152 %\n"
     ]
    }
   ],
   "source": [
    "# WITHOUT BOOSTING\n",
    "svclassifier = SVC(gamma='scale',kernel='poly', degree = 2, shrinking = True)\n",
    "svclassifier.fit(dftrain, y_train)\n",
    "y_pred = svclassifier.predict(dfeval)\n",
    "\n",
    "print(\"NO BOOSTING. \",\"Kernel: poly\",\"\\t\",\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred)*100,\"%\")\n",
    "\n",
    "# WITH BOOSTING\n",
    "svcpoly = SVC(probability=True, gamma='scale',kernel='poly', degree=2)\n",
    "boostpoly = AdaBoostClassifier(n_estimators=90, base_estimator=svcpoly,learning_rate=.01)\n",
    "boostpolymodel = boostpoly.fit(dftrain, y_train)\n",
    "y_pred = boostpolymodel.predict(dfeval)\n",
    "\n",
    "print(\"WITH BOOSTING. \",\"Kernel: poly\",\"\\t\",\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO BOOSTING.  Kernel: rbf \t Accuracy: 68.93939393939394 %\n",
      "WITH BOOSTING.  Kernel: rbf \t Accuracy: 68.93939393939394 %\n"
     ]
    }
   ],
   "source": [
    "# WITHOUT BOOSTING\n",
    "svclassifier2 = SVC(gamma='scale',kernel='rbf')\n",
    "svclassifier2.fit(dftrain, y_train)\n",
    "y_pred = svclassifier2.predict(dfeval)\n",
    "\n",
    "print(\"NO BOOSTING. \",\"Kernel: rbf\",\"\\t\",\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred)*100,\"%\")\n",
    "\n",
    "# WITH BOOSTING\n",
    "svcRBF = SVC(probability=True, gamma='scale',kernel='rbf')\n",
    "boostRBF = AdaBoostClassifier(n_estimators=90, base_estimator=svcRBF,learning_rate=.01)\n",
    "boostRBFmodel = boostRBF.fit(dftrain, y_train)\n",
    "y_pred = boostRBFmodel.predict(dfeval)\n",
    "\n",
    "print(\"WITH BOOSTING. \",\"Kernel: rbf\",\"\\t\",\"Accuracy:\",metrics.accuracy_score(y_eval, y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{TASK 5. }}$ *Use your observations on the dataset, and using the above methods, try to improve the accuracy as much as you can. An ideal target is more than 85%.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's all yours now, get the best possible accuracy in doing so understand the concepts we learnt in class. Hold on fellas, one more thing, don't push yourself so hard to get 100% though!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{blue}{\\textit{Explanation: }}$\n",
    "\n",
    "From Task 4, we saw that applying AdaBoost to an SVM classifier did little to change the accuracy. Therefore, we should look at our options from Tasks 1-3. From all the models presented during Tasks 1-3, SVM with poly (deg-2) kernel had the highest accuracy, followed by AdaBoost for a decision tree. \n",
    "\n",
    "However, performing one run for SVM-poly took approximately 10 seconds, and iterating through at least 100 different hyperparameter combinations might not be ideal when considering computational time and power consumption required for the user's personal device (as well as the limitations of the CPU cores). Therefore, we will consider using the AdaBoost-ed decision trees (AdaBoost-DT) classifier in trying to increase its accuracy to at least 85%. \n",
    "\n",
    "Note that the provided AdaBoost-DT code block in Task 2 used hyper-parameters max_depth=3, n_estimators=50, and learning_rate=1. As previously discussed in Task 2, we also saw that max_depth values of 100-500 were ideal. For initial runs, we should keep n_estimators and learning_rate values somewhat close to the original code block.\n",
    "\n",
    "Therefore, it is best to use max_depth values of 100-500, n_estimators of 50-150, and learning_rate values of 0.5-1.5. We fine-tune the model even more as shown below.\n",
    "\n",
    "To view all results, de-comment the print statement and comment out the modulo if-statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.625000 percent completed. Time elapsed: 9.786393s\n",
      "31.250000 percent completed. Time elapsed: 20.482819s\n",
      "46.875000 percent completed. Time elapsed: 31.446465s\n",
      "62.500000 percent completed. Time elapsed: 42.598741s\n",
      "78.125000 percent completed. Time elapsed: 52.346592s\n",
      "93.750000 percent completed. Time elapsed: 62.319366s\n",
      "Test complete. Time elapsed: 68.075758s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_init = time.time()\n",
    "\n",
    "# Fine-tune hyper-parameter ranges\n",
    "depth_vals = np.arange(start=100, stop=500, step=50)\n",
    "est_vals = np.arange(start=50, stop=150, step=25)\n",
    "lr_vals = np.arange(start=0.5, stop=1.5, step=0.1)\n",
    "\n",
    "# Setup\n",
    "results = {}\n",
    "best_val = -1 \n",
    "best_dep, best_est, best_lr = -1, -1, -1\n",
    "best_abc = None\n",
    "\n",
    "# Create set of all possible hyper-parameter combos\n",
    "hyperparams = [(i,j,k) for i in depth_vals for j in est_vals for k in lr_vals]\n",
    "total = len(depth_vals) * len(est_vals) * len(lr_vals)\n",
    "count = 0\n",
    "\n",
    "# Test each combo\n",
    "for (i,j,k) in hyperparams:\n",
    "    abc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=i),n_estimators=j,\n",
    "                         learning_rate=k)\n",
    "    model = abc.fit(dftrain, y_train)\n",
    "    y_pred = model.predict(dfeval)\n",
    "    accur_val = metrics.accuracy_score(y_eval, y_pred)\n",
    "    results[(i,j,k)] = accur_val\n",
    "    # print(\"Max Depth:\", i, \"Estimators:\", j, \"Learning Rate:\", k, \"Accuracy:\",accur_val*100,\"%\")\n",
    "    count += 1\n",
    "    if (count % 50) == 0:\n",
    "        print(\"%f percent completed. Time elapsed: %fs\" % (count/total*100, time.time()-t_init))\n",
    "    if accur_val > best_val:\n",
    "        best_val = accur_val\n",
    "        best_dep, best_est, best_lr = i,j,k\n",
    "        best_abc = abc\n",
    "    \n",
    "\n",
    "t_fin = time.time()\n",
    "print(\"Test complete. Time elapsed: %fs\" % (t_fin-t_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 85.22727272727273 %\n",
      "Max Depth: 100 \t Estimators: 100 \t Learning Rate: 0.7999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Best accuracy:\", best_val*100, \"%\")\n",
    "print(\"Max Depth:\", best_dep, \"\\t\", \"Estimators:\", best_est, \"\\t\", \"Learning Rate:\", best_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
